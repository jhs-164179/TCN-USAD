{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-10T07:30:16.205789600Z",
     "start_time": "2024-06-10T07:30:13.206140400Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from models import AE, USAD"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# mode == MLP(Dense | Linear)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a36c7877ade7fcdb"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# test1 AE(AutoEncoder) with MLP\n",
    "\n",
    "# input data(2dim, (B, T))\n",
    "x_data = np.random.sample((100, 24)).astype(np.float32)\n",
    "# y_data = np.random.sample((100, 24)).astype(np.float32)\n",
    "\n",
    "# make dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_data, x_data))\n",
    "dataset = dataset.batch(batch_size=32).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T07:30:16.862054Z",
     "start_time": "2024-06-10T07:30:16.830774Z"
    }
   },
   "id": "58c8bd93c7103304"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train_loss: 0.2275 | 1.08 sec\n",
      "epoch 2 train_loss: 0.1045 | 0.06 sec\n",
      "epoch 3 train_loss: 0.0928 | 0.08 sec\n",
      "epoch 4 train_loss: 0.1028 | 0.06 sec\n",
      "epoch 5 train_loss: 0.0885 | 0.08 sec\n",
      "epoch 6 train_loss: 0.0821 | 0.06 sec\n",
      "epoch 7 train_loss: 0.0842 | 0.08 sec\n",
      "epoch 8 train_loss: 0.0843 | 0.06 sec\n",
      "epoch 9 train_loss: 0.0819 | 0.08 sec\n",
      "epoch 10 train_loss: 0.0807 | 0.06 sec\n",
      "epoch 11 train_loss: 0.0810 | 0.08 sec\n",
      "epoch 12 train_loss: 0.0807 | 0.06 sec\n",
      "epoch 13 train_loss: 0.0800 | 0.08 sec\n",
      "epoch 14 train_loss: 0.0798 | 0.06 sec\n",
      "epoch 15 train_loss: 0.0797 | 0.08 sec\n",
      "epoch 16 train_loss: 0.0795 | 0.06 sec\n",
      "epoch 17 train_loss: 0.0794 | 0.08 sec\n",
      "epoch 18 train_loss: 0.0793 | 0.06 sec\n",
      "epoch 19 train_loss: 0.0792 | 0.08 sec\n",
      "epoch 20 train_loss: 0.0792 | 0.06 sec\n",
      "epoch 21 train_loss: 0.0791 | 0.06 sec\n",
      "epoch 22 train_loss: 0.0791 | 0.08 sec\n",
      "epoch 23 train_loss: 0.0790 | 0.06 sec\n",
      "epoch 24 train_loss: 0.0790 | 0.08 sec\n",
      "epoch 25 train_loss: 0.0789 | 0.06 sec\n",
      "epoch 26 train_loss: 0.0789 | 0.06 sec\n",
      "epoch 27 train_loss: 0.0789 | 0.08 sec\n",
      "epoch 28 train_loss: 0.0788 | 0.06 sec\n",
      "epoch 29 train_loss: 0.0788 | 0.08 sec\n",
      "epoch 30 train_loss: 0.0788 | 0.06 sec\n",
      "epoch 31 train_loss: 0.0787 | 0.08 sec\n",
      "epoch 32 train_loss: 0.0787 | 0.06 sec\n",
      "epoch 33 train_loss: 0.0787 | 0.06 sec\n",
      "epoch 34 train_loss: 0.0787 | 0.08 sec\n",
      "epoch 35 train_loss: 0.0786 | 0.06 sec\n",
      "epoch 36 train_loss: 0.0786 | 0.06 sec\n",
      "epoch 37 train_loss: 0.0786 | 0.08 sec\n",
      "epoch 38 train_loss: 0.0786 | 0.06 sec\n",
      "epoch 39 train_loss: 0.0785 | 0.08 sec\n",
      "epoch 40 train_loss: 0.0785 | 0.06 sec\n",
      "epoch 41 train_loss: 0.0785 | 0.08 sec\n",
      "epoch 42 train_loss: 0.0785 | 0.06 sec\n",
      "epoch 43 train_loss: 0.0785 | 0.06 sec\n",
      "epoch 44 train_loss: 0.0784 | 0.08 sec\n",
      "epoch 45 train_loss: 0.0784 | 0.06 sec\n",
      "epoch 46 train_loss: 0.0784 | 0.06 sec\n",
      "epoch 47 train_loss: 0.0784 | 0.08 sec\n",
      "epoch 48 train_loss: 0.0784 | 0.06 sec\n",
      "epoch 49 train_loss: 0.0784 | 0.08 sec\n",
      "epoch 50 train_loss: 0.0784 | 0.06 sec\n",
      "Train time: 4.4686\n"
     ]
    }
   ],
   "source": [
    "# input_dim = seq_length(T)\n",
    "# z_dim = output of encoder(size of latent vector)\n",
    "# d_hidden_dim = decoder hidden dim\n",
    "autoencoder = AE(input_dim=24, z_dim=32, d_hidden_dim=64, mode='Dense')\n",
    "hist = autoencoder.fit(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T07:30:21.424443500Z",
     "start_time": "2024-06-10T07:30:16.862054Z"
    }
   },
   "id": "c63d2f1aada9394f"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train1_loss: 0.0817 | train2_loss: 0.0815 | 0.27 sec\n",
      "epoch 2 train1_loss: 0.0809 | train2_loss: -0.0001 | 0.13 sec\n",
      "epoch 3 train1_loss: 0.0807 | train2_loss: -0.0271 | 0.14 sec\n",
      "epoch 4 train1_loss: 0.0806 | train2_loss: -0.0406 | 0.14 sec\n",
      "epoch 5 train1_loss: 0.0805 | train2_loss: -0.0486 | 0.14 sec\n",
      "epoch 6 train1_loss: 0.0806 | train2_loss: -0.0541 | 0.14 sec\n",
      "epoch 7 train1_loss: 0.0807 | train2_loss: -0.0581 | 0.14 sec\n",
      "epoch 8 train1_loss: 0.0809 | train2_loss: -0.0612 | 0.14 sec\n",
      "epoch 9 train1_loss: 0.0813 | train2_loss: -0.0637 | 0.14 sec\n",
      "epoch 10 train1_loss: 0.0818 | train2_loss: -0.0660 | 0.12 sec\n",
      "epoch 11 train1_loss: 0.0826 | train2_loss: -0.0683 | 0.14 sec\n",
      "epoch 12 train1_loss: 0.0839 | train2_loss: -0.0707 | 0.14 sec\n",
      "epoch 13 train1_loss: 0.0858 | train2_loss: -0.0735 | 0.14 sec\n",
      "epoch 14 train1_loss: 0.0885 | train2_loss: -0.0768 | 0.14 sec\n",
      "epoch 15 train1_loss: 0.0919 | train2_loss: -0.0807 | 0.14 sec\n",
      "epoch 16 train1_loss: 0.0959 | train2_loss: -0.0851 | 0.14 sec\n",
      "epoch 17 train1_loss: 0.1004 | train2_loss: -0.0897 | 0.13 sec\n",
      "epoch 18 train1_loss: 0.1046 | train2_loss: -0.0938 | 0.14 sec\n",
      "epoch 19 train1_loss: 0.1079 | train2_loss: -0.0968 | 0.14 sec\n",
      "epoch 20 train1_loss: 0.1103 | train2_loss: -0.0988 | 0.14 sec\n",
      "epoch 21 train1_loss: 0.1124 | train2_loss: -0.1004 | 0.14 sec\n",
      "epoch 22 train1_loss: 0.1169 | train2_loss: -0.1044 | 0.14 sec\n",
      "epoch 23 train1_loss: 0.1225 | train2_loss: -0.1097 | 0.14 sec\n",
      "epoch 24 train1_loss: 0.1290 | train2_loss: -0.1160 | 0.14 sec\n",
      "epoch 25 train1_loss: 0.1364 | train2_loss: -0.1232 | 0.14 sec\n",
      "epoch 26 train1_loss: 0.1450 | train2_loss: -0.1317 | 0.13 sec\n",
      "epoch 27 train1_loss: 0.1556 | train2_loss: -0.1423 | 0.15 sec\n",
      "epoch 28 train1_loss: 0.1684 | train2_loss: -0.1551 | 0.13 sec\n",
      "epoch 29 train1_loss: 0.1829 | train2_loss: -0.1697 | 0.14 sec\n",
      "epoch 30 train1_loss: 0.1986 | train2_loss: -0.1855 | 0.14 sec\n",
      "epoch 31 train1_loss: 0.2150 | train2_loss: -0.2021 | 0.14 sec\n",
      "epoch 32 train1_loss: 0.2318 | train2_loss: -0.2191 | 0.13 sec\n",
      "epoch 33 train1_loss: 0.2496 | train2_loss: -0.2370 | 0.14 sec\n",
      "epoch 34 train1_loss: 0.2662 | train2_loss: -0.2538 | 0.14 sec\n",
      "epoch 35 train1_loss: 0.2808 | train2_loss: -0.2687 | 0.14 sec\n",
      "epoch 36 train1_loss: 0.2930 | train2_loss: -0.2811 | 0.14 sec\n",
      "epoch 37 train1_loss: 0.3029 | train2_loss: -0.2911 | 0.14 sec\n",
      "epoch 38 train1_loss: 0.3109 | train2_loss: -0.2993 | 0.14 sec\n",
      "epoch 39 train1_loss: 0.3167 | train2_loss: -0.3053 | 0.14 sec\n",
      "epoch 40 train1_loss: 0.3213 | train2_loss: -0.3101 | 0.12 sec\n",
      "epoch 41 train1_loss: 0.3250 | train2_loss: -0.3141 | 0.14 sec\n",
      "epoch 42 train1_loss: 0.3279 | train2_loss: -0.3172 | 0.14 sec\n",
      "epoch 43 train1_loss: 0.3303 | train2_loss: -0.3197 | 0.14 sec\n",
      "epoch 44 train1_loss: 0.3323 | train2_loss: -0.3219 | 0.12 sec\n",
      "epoch 45 train1_loss: 0.3341 | train2_loss: -0.3239 | 0.14 sec\n",
      "epoch 46 train1_loss: 0.3358 | train2_loss: -0.3257 | 0.14 sec\n",
      "epoch 47 train1_loss: 0.3373 | train2_loss: -0.3274 | 0.14 sec\n",
      "epoch 48 train1_loss: 0.3385 | train2_loss: -0.3288 | 0.14 sec\n",
      "epoch 49 train1_loss: 0.3394 | train2_loss: -0.3299 | 0.14 sec\n",
      "epoch 50 train1_loss: 0.3401 | train2_loss: -0.3308 | 0.13 sec\n",
      "Train time: 7.0313\n"
     ]
    }
   ],
   "source": [
    "# test1 USAD(UnSupervisedAnomalyDetection) with MLP\n",
    "\n",
    "# input_dim = seq_length(T)\n",
    "# z_dim = output of encoder(size of latent vector)\n",
    "# e_hidden_dims = encoder hidden dims(list)\n",
    "# d_hidden_dims = decoder hidden dims(list)\n",
    "usad = USAD(24, 32, [64, 32], [32, 64], mode='Dense')\n",
    "hist2 = usad.fit(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T07:30:28.502629300Z",
     "start_time": "2024-06-10T07:30:21.424443500Z"
    }
   },
   "id": "2298b4a7ee3c90a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# mode == (LSTM or GRU)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc3c5c44b01f130e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# test1 AE(AutoEncoder) with LSTM or GRU\n",
    "\n",
    "# input data(3dim, (B, T, C) | C=number of features)\n",
    "x_data = np.random.sample((100, 24, 1)).astype(np.float32)\n",
    "# y_data = np.random.sample((100, 24, 1)).astype(np.float32)\n",
    "\n",
    "# make dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_data, x_data))\n",
    "dataset = dataset.batch(batch_size=32).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T07:30:58.076750500Z",
     "start_time": "2024-06-10T07:30:58.050004400Z"
    }
   },
   "id": "859376baf62cdf3a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train_loss: 0.3112 | 1.44 sec\n",
      "epoch 2 train_loss: 0.2143 | 0.14 sec\n",
      "epoch 3 train_loss: 0.1251 | 0.16 sec\n",
      "epoch 4 train_loss: 0.1237 | 0.14 sec\n",
      "epoch 5 train_loss: 0.1064 | 0.16 sec\n",
      "epoch 6 train_loss: 0.1024 | 0.14 sec\n",
      "epoch 7 train_loss: 0.1017 | 0.16 sec\n",
      "epoch 8 train_loss: 0.0959 | 0.16 sec\n",
      "epoch 9 train_loss: 0.0943 | 0.14 sec\n",
      "epoch 10 train_loss: 0.0941 | 0.16 sec\n",
      "epoch 11 train_loss: 0.0919 | 0.16 sec\n",
      "epoch 12 train_loss: 0.0912 | 0.14 sec\n",
      "epoch 13 train_loss: 0.0900 | 0.16 sec\n",
      "epoch 14 train_loss: 0.0891 | 0.16 sec\n",
      "epoch 15 train_loss: 0.0887 | 0.16 sec\n",
      "epoch 16 train_loss: 0.0879 | 0.16 sec\n",
      "epoch 17 train_loss: 0.0874 | 0.16 sec\n",
      "epoch 18 train_loss: 0.0868 | 0.16 sec\n",
      "epoch 19 train_loss: 0.0865 | 0.16 sec\n",
      "epoch 20 train_loss: 0.0861 | 0.16 sec\n",
      "epoch 21 train_loss: 0.0857 | 0.16 sec\n",
      "epoch 22 train_loss: 0.0854 | 0.14 sec\n",
      "epoch 23 train_loss: 0.0851 | 0.19 sec\n",
      "epoch 24 train_loss: 0.0847 | 0.14 sec\n",
      "epoch 25 train_loss: 0.0844 | 0.17 sec\n",
      "epoch 26 train_loss: 0.0841 | 0.16 sec\n",
      "epoch 27 train_loss: 0.0838 | 0.16 sec\n",
      "epoch 28 train_loss: 0.0835 | 0.14 sec\n",
      "epoch 29 train_loss: 0.0832 | 0.16 sec\n",
      "epoch 30 train_loss: 0.0829 | 0.14 sec\n",
      "epoch 31 train_loss: 0.0825 | 0.16 sec\n",
      "epoch 32 train_loss: 0.0822 | 0.16 sec\n",
      "epoch 33 train_loss: 0.0819 | 0.14 sec\n",
      "epoch 34 train_loss: 0.0817 | 0.16 sec\n",
      "epoch 35 train_loss: 0.0815 | 0.16 sec\n",
      "epoch 36 train_loss: 0.0813 | 0.14 sec\n",
      "epoch 37 train_loss: 0.0812 | 0.16 sec\n",
      "epoch 38 train_loss: 0.0812 | 0.16 sec\n",
      "epoch 39 train_loss: 0.0813 | 0.16 sec\n",
      "epoch 40 train_loss: 0.0813 | 0.14 sec\n",
      "epoch 41 train_loss: 0.0811 | 0.17 sec\n",
      "epoch 42 train_loss: 0.0809 | 0.14 sec\n",
      "epoch 43 train_loss: 0.0809 | 0.16 sec\n",
      "epoch 44 train_loss: 0.0809 | 0.16 sec\n",
      "epoch 45 train_loss: 0.0808 | 0.14 sec\n",
      "epoch 46 train_loss: 0.0808 | 0.16 sec\n",
      "epoch 47 train_loss: 0.0808 | 0.16 sec\n",
      "epoch 48 train_loss: 0.0807 | 0.16 sec\n",
      "epoch 49 train_loss: 0.0807 | 0.16 sec\n",
      "epoch 50 train_loss: 0.0807 | 0.14 sec\n",
      "Train time: 8.9216\n"
     ]
    }
   ],
   "source": [
    "# input_dim = seq_length(T)\n",
    "# z_dim = output of encoder(size of latent vector)\n",
    "# d_hidden_dim = decoder hidden dim\n",
    "autoencoder = AE(24, 32, 64)\n",
    "hist = autoencoder.fit(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T07:31:07.533867Z",
     "start_time": "2024-06-10T07:30:58.572485200Z"
    }
   },
   "id": "ac260d32306b03c7"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train1_loss: 0.0849 | train2_loss: 0.0849 | 1.55 sec\n",
      "epoch 2 train1_loss: 0.0849 | train2_loss: -0.0001 | 0.44 sec\n",
      "epoch 3 train1_loss: 0.0849 | train2_loss: -0.0284 | 0.44 sec\n",
      "epoch 4 train1_loss: 0.0849 | train2_loss: -0.0425 | 0.44 sec\n",
      "epoch 5 train1_loss: 0.0849 | train2_loss: -0.0510 | 0.44 sec\n",
      "epoch 6 train1_loss: 0.0849 | train2_loss: -0.0567 | 0.44 sec\n",
      "epoch 7 train1_loss: 0.0849 | train2_loss: -0.0607 | 0.44 sec\n",
      "epoch 8 train1_loss: 0.0849 | train2_loss: -0.0637 | 0.44 sec\n",
      "epoch 9 train1_loss: 0.0849 | train2_loss: -0.0661 | 0.44 sec\n",
      "epoch 10 train1_loss: 0.0849 | train2_loss: -0.0680 | 0.45 sec\n",
      "epoch 11 train1_loss: 0.0849 | train2_loss: -0.0695 | 0.45 sec\n",
      "epoch 12 train1_loss: 0.0848 | train2_loss: -0.0708 | 0.44 sec\n",
      "epoch 13 train1_loss: 0.0848 | train2_loss: -0.0718 | 0.47 sec\n",
      "epoch 14 train1_loss: 0.0847 | train2_loss: -0.0727 | 0.44 sec\n",
      "epoch 15 train1_loss: 0.0846 | train2_loss: -0.0734 | 0.44 sec\n",
      "epoch 16 train1_loss: 0.0844 | train2_loss: -0.0739 | 0.45 sec\n",
      "epoch 17 train1_loss: 0.0840 | train2_loss: -0.0742 | 0.44 sec\n",
      "epoch 18 train1_loss: 0.0836 | train2_loss: -0.0743 | 0.44 sec\n",
      "epoch 19 train1_loss: 0.0837 | train2_loss: -0.0747 | 0.44 sec\n",
      "epoch 20 train1_loss: 0.0837 | train2_loss: -0.0750 | 0.44 sec\n",
      "epoch 21 train1_loss: 0.0836 | train2_loss: -0.0755 | 0.44 sec\n",
      "epoch 22 train1_loss: 0.0837 | train2_loss: -0.0759 | 0.44 sec\n",
      "epoch 23 train1_loss: 0.0844 | train2_loss: -0.0769 | 0.44 sec\n",
      "epoch 24 train1_loss: 0.0835 | train2_loss: -0.0766 | 0.44 sec\n",
      "epoch 25 train1_loss: 0.0837 | train2_loss: -0.0770 | 0.44 sec\n",
      "epoch 26 train1_loss: 0.0840 | train2_loss: -0.0776 | 0.45 sec\n",
      "epoch 27 train1_loss: 0.0845 | train2_loss: -0.0783 | 0.44 sec\n",
      "epoch 28 train1_loss: 0.0847 | train2_loss: -0.0787 | 0.44 sec\n",
      "epoch 29 train1_loss: 0.0850 | train2_loss: -0.0792 | 0.44 sec\n",
      "epoch 30 train1_loss: 0.0852 | train2_loss: -0.0796 | 0.44 sec\n",
      "epoch 31 train1_loss: 0.0853 | train2_loss: -0.0798 | 0.44 sec\n",
      "epoch 32 train1_loss: 0.0861 | train2_loss: -0.0808 | 0.44 sec\n",
      "epoch 33 train1_loss: 0.0870 | train2_loss: -0.0818 | 0.44 sec\n",
      "epoch 34 train1_loss: 0.0880 | train2_loss: -0.0830 | 0.44 sec\n",
      "epoch 35 train1_loss: 0.0893 | train2_loss: -0.0843 | 0.45 sec\n",
      "epoch 36 train1_loss: 0.0911 | train2_loss: -0.0862 | 0.44 sec\n",
      "epoch 37 train1_loss: 0.0943 | train2_loss: -0.0895 | 0.44 sec\n",
      "epoch 38 train1_loss: 0.0981 | train2_loss: -0.0934 | 0.45 sec\n",
      "epoch 39 train1_loss: 0.1023 | train2_loss: -0.0976 | 0.44 sec\n",
      "epoch 40 train1_loss: 0.1039 | train2_loss: -0.0992 | 0.45 sec\n",
      "epoch 41 train1_loss: 0.1013 | train2_loss: -0.0968 | 0.44 sec\n",
      "epoch 42 train1_loss: 0.0973 | train2_loss: -0.0930 | 0.44 sec\n",
      "epoch 43 train1_loss: 0.0964 | train2_loss: -0.0922 | 0.44 sec\n",
      "epoch 44 train1_loss: 0.0953 | train2_loss: -0.0911 | 0.44 sec\n",
      "epoch 45 train1_loss: 0.0952 | train2_loss: -0.0912 | 0.44 sec\n",
      "epoch 46 train1_loss: 0.0973 | train2_loss: -0.0933 | 0.44 sec\n",
      "epoch 47 train1_loss: 0.1041 | train2_loss: -0.1000 | 0.45 sec\n",
      "epoch 48 train1_loss: 0.1131 | train2_loss: -0.1089 | 0.44 sec\n",
      "epoch 49 train1_loss: 0.1159 | train2_loss: -0.1117 | 0.44 sec\n",
      "epoch 50 train1_loss: 0.1140 | train2_loss: -0.1100 | 0.45 sec\n",
      "Train time: 23.1561\n"
     ]
    }
   ],
   "source": [
    "# test2 USAD(UnSupervisedAnomalyDetection) with LSTM or GRU\n",
    "\n",
    "# input_dim = seq_length(T)\n",
    "# z_dim = output of encoder(size of latent vector)\n",
    "# e_hidden_dims = encoder hidden dims(not list)\n",
    "# d_hidden_dims = decoder hidden dims(not list)\n",
    "usad = USAD(24, 32, 32, 32)\n",
    "hist2 = usad.fit(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T07:31:39.549805200Z",
     "start_time": "2024-06-10T07:31:16.362249100Z"
    }
   },
   "id": "2be87845b0abbdee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# mode == TCN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eab2751654dde7b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# test1 AE(AutoEncoder) with TCN\n",
    "\n",
    "# input data(3dim, (B, T, C) | C=number of features)\n",
    "x_data = np.random.sample((100, 24, 1)).astype(np.float32)\n",
    "# y_data = np.random.sample((100, 24, 1)).astype(np.float32)\n",
    "\n",
    "# make dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_data, x_data))\n",
    "dataset = dataset.batch(batch_size=32).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T07:31:54.971709100Z",
     "start_time": "2024-06-10T07:31:54.955719900Z"
    }
   },
   "id": "4d79c707af451366"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train_loss: 2.3676 | 5.09 sec\n",
      "epoch 2 train_loss: 1.4566 | 0.44 sec\n",
      "epoch 3 train_loss: 0.3675 | 0.45 sec\n",
      "epoch 4 train_loss: 0.3831 | 0.44 sec\n",
      "epoch 5 train_loss: 0.4480 | 0.45 sec\n",
      "epoch 6 train_loss: 0.2461 | 0.44 sec\n",
      "epoch 7 train_loss: 0.1825 | 0.45 sec\n",
      "epoch 8 train_loss: 0.1436 | 0.45 sec\n",
      "epoch 9 train_loss: 0.1200 | 0.44 sec\n",
      "epoch 10 train_loss: 0.1073 | 0.45 sec\n",
      "epoch 11 train_loss: 0.0968 | 0.45 sec\n",
      "epoch 12 train_loss: 0.0914 | 0.45 sec\n",
      "epoch 13 train_loss: 0.0855 | 0.47 sec\n",
      "epoch 14 train_loss: 0.0809 | 0.48 sec\n",
      "epoch 15 train_loss: 0.0789 | 0.47 sec\n",
      "epoch 16 train_loss: 0.0755 | 0.47 sec\n",
      "epoch 17 train_loss: 0.0730 | 0.45 sec\n",
      "epoch 18 train_loss: 0.0717 | 0.45 sec\n",
      "epoch 19 train_loss: 0.0700 | 0.45 sec\n",
      "epoch 20 train_loss: 0.0685 | 0.47 sec\n",
      "epoch 21 train_loss: 0.0674 | 0.47 sec\n",
      "epoch 22 train_loss: 0.0660 | 0.45 sec\n",
      "epoch 23 train_loss: 0.0651 | 0.47 sec\n",
      "epoch 24 train_loss: 0.0639 | 0.44 sec\n",
      "epoch 25 train_loss: 0.0631 | 0.45 sec\n",
      "epoch 26 train_loss: 0.0621 | 0.45 sec\n",
      "epoch 27 train_loss: 0.0613 | 0.44 sec\n",
      "epoch 28 train_loss: 0.0604 | 0.45 sec\n",
      "epoch 29 train_loss: 0.0597 | 0.45 sec\n",
      "epoch 30 train_loss: 0.0589 | 0.45 sec\n",
      "epoch 31 train_loss: 0.0581 | 0.45 sec\n",
      "epoch 32 train_loss: 0.0573 | 0.45 sec\n",
      "epoch 33 train_loss: 0.0567 | 0.44 sec\n",
      "epoch 34 train_loss: 0.0560 | 0.45 sec\n",
      "epoch 35 train_loss: 0.0553 | 0.45 sec\n",
      "epoch 36 train_loss: 0.0547 | 0.44 sec\n",
      "epoch 37 train_loss: 0.0541 | 0.45 sec\n",
      "epoch 38 train_loss: 0.0535 | 0.48 sec\n",
      "epoch 39 train_loss: 0.0528 | 0.45 sec\n",
      "epoch 40 train_loss: 0.0522 | 0.45 sec\n",
      "epoch 41 train_loss: 0.0517 | 0.45 sec\n",
      "epoch 42 train_loss: 0.0511 | 0.47 sec\n",
      "epoch 43 train_loss: 0.0505 | 0.45 sec\n",
      "epoch 44 train_loss: 0.0500 | 0.45 sec\n",
      "epoch 45 train_loss: 0.0495 | 0.45 sec\n",
      "epoch 46 train_loss: 0.0489 | 0.47 sec\n",
      "epoch 47 train_loss: 0.0485 | 0.47 sec\n",
      "epoch 48 train_loss: 0.0478 | 0.45 sec\n",
      "epoch 49 train_loss: 0.0474 | 0.44 sec\n",
      "epoch 50 train_loss: 0.0468 | 0.45 sec\n",
      "Train time: 27.3594\n"
     ]
    }
   ],
   "source": [
    "# input_dim = seq_length(T)\n",
    "# z_dim = output of encoder(size of latent vector)\n",
    "# d_hidden_dim = decoder hidden dim\n",
    "# e_hidden_dim = encoder hidden dim(for TCN)\n",
    "# dilations = dilation rates(for TCN | list)\n",
    "autoencoder = AE(24, 32, 64, 64, [1, 2, 4, 8, 16, 23], mode='TCN')\n",
    "hist = autoencoder.fit(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T07:32:23.627883800Z",
     "start_time": "2024-06-10T07:31:56.205866700Z"
    }
   },
   "id": "599f7d5a56f3acdc"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train1_loss: 0.1015 | train2_loss: 0.1038 | 5.38 sec\n",
      "epoch 2 train1_loss: 0.0939 | train2_loss: 0.0007 | 1.23 sec\n",
      "epoch 3 train1_loss: 0.0921 | train2_loss: -0.0290 | 1.22 sec\n",
      "epoch 4 train1_loss: 0.1035 | train2_loss: -0.0572 | 1.22 sec\n",
      "epoch 5 train1_loss: 0.1361 | train2_loss: -0.0941 | 1.22 sec\n",
      "epoch 6 train1_loss: 0.1666 | train2_loss: -0.1207 | 1.22 sec\n",
      "epoch 7 train1_loss: 0.2209 | train2_loss: -0.1617 | 1.22 sec\n",
      "epoch 8 train1_loss: 0.2697 | train2_loss: -0.2037 | 1.22 sec\n",
      "epoch 9 train1_loss: 0.3076 | train2_loss: -0.2437 | 1.23 sec\n",
      "epoch 10 train1_loss: 0.3237 | train2_loss: -0.2662 | 1.22 sec\n",
      "epoch 11 train1_loss: 0.3229 | train2_loss: -0.2748 | 1.22 sec\n",
      "epoch 12 train1_loss: 0.3209 | train2_loss: -0.2803 | 1.23 sec\n",
      "epoch 13 train1_loss: 0.3203 | train2_loss: -0.2848 | 1.33 sec\n",
      "epoch 14 train1_loss: 0.3191 | train2_loss: -0.2886 | 1.22 sec\n",
      "epoch 15 train1_loss: 0.3193 | train2_loss: -0.2919 | 1.22 sec\n",
      "epoch 16 train1_loss: 0.3168 | train2_loss: -0.2920 | 1.23 sec\n",
      "epoch 17 train1_loss: 0.3101 | train2_loss: -0.2853 | 1.22 sec\n",
      "epoch 18 train1_loss: 0.3198 | train2_loss: -0.2945 | 1.20 sec\n",
      "epoch 19 train1_loss: 0.3257 | train2_loss: -0.3009 | 1.22 sec\n",
      "epoch 20 train1_loss: 0.3260 | train2_loss: -0.3020 | 1.20 sec\n",
      "epoch 21 train1_loss: 0.3204 | train2_loss: -0.2983 | 1.20 sec\n",
      "epoch 22 train1_loss: 0.3181 | train2_loss: -0.2977 | 1.22 sec\n",
      "epoch 23 train1_loss: 0.3247 | train2_loss: -0.3050 | 1.20 sec\n",
      "epoch 24 train1_loss: 0.3241 | train2_loss: -0.3048 | 1.20 sec\n",
      "epoch 25 train1_loss: 0.3260 | train2_loss: -0.3081 | 1.22 sec\n",
      "epoch 26 train1_loss: 0.3265 | train2_loss: -0.3097 | 1.20 sec\n",
      "epoch 27 train1_loss: 0.3267 | train2_loss: -0.3106 | 1.20 sec\n",
      "epoch 28 train1_loss: 0.3269 | train2_loss: -0.3115 | 1.22 sec\n",
      "epoch 29 train1_loss: 0.3271 | train2_loss: -0.3123 | 1.22 sec\n",
      "epoch 30 train1_loss: 0.3272 | train2_loss: -0.3131 | 1.22 sec\n",
      "epoch 31 train1_loss: 0.3274 | train2_loss: -0.3138 | 1.22 sec\n",
      "epoch 32 train1_loss: 0.3277 | train2_loss: -0.3144 | 1.20 sec\n",
      "epoch 33 train1_loss: 0.3279 | train2_loss: -0.3151 | 1.22 sec\n",
      "epoch 34 train1_loss: 0.3281 | train2_loss: -0.3157 | 1.20 sec\n",
      "epoch 35 train1_loss: 0.3283 | train2_loss: -0.3162 | 1.22 sec\n",
      "epoch 36 train1_loss: 0.3284 | train2_loss: -0.3168 | 1.22 sec\n",
      "epoch 37 train1_loss: 0.3286 | train2_loss: -0.3173 | 1.20 sec\n",
      "epoch 38 train1_loss: 0.3288 | train2_loss: -0.3178 | 1.21 sec\n",
      "epoch 39 train1_loss: 0.3289 | train2_loss: -0.3182 | 1.20 sec\n",
      "epoch 40 train1_loss: 0.3291 | train2_loss: -0.3186 | 1.34 sec\n",
      "epoch 41 train1_loss: 0.3292 | train2_loss: -0.3190 | 1.23 sec\n",
      "epoch 42 train1_loss: 0.3294 | train2_loss: -0.3194 | 1.23 sec\n",
      "epoch 43 train1_loss: 0.3295 | train2_loss: -0.3198 | 1.22 sec\n",
      "epoch 44 train1_loss: 0.3296 | train2_loss: -0.3202 | 1.20 sec\n",
      "epoch 45 train1_loss: 0.3298 | train2_loss: -0.3205 | 1.20 sec\n",
      "epoch 46 train1_loss: 0.3299 | train2_loss: -0.3208 | 1.20 sec\n",
      "epoch 47 train1_loss: 0.3300 | train2_loss: -0.3211 | 1.20 sec\n",
      "epoch 48 train1_loss: 0.3301 | train2_loss: -0.3214 | 1.20 sec\n",
      "epoch 49 train1_loss: 0.3302 | train2_loss: -0.3217 | 1.20 sec\n",
      "epoch 50 train1_loss: 0.3303 | train2_loss: -0.3220 | 1.22 sec\n",
      "Train time: 65.1406\n"
     ]
    }
   ],
   "source": [
    "# test2 USAD(UnSupervisedAnomalyDetection) with TCN\n",
    "\n",
    "# input_dim = seq_length(T)\n",
    "# z_dim = output of encoder(size of latent vector)\n",
    "# e_hidden_dims = encoder hidden dims(not list)\n",
    "# d_hidden_dims = decoder hidden dims(not list)\n",
    "# dilations = dilation rates(for TCN | list)\n",
    "usad = USAD(24, 32, 32, 32, [1, 2, 4, 8, 16, 23], mode='TCN')\n",
    "hist2 = usad.fit(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T07:33:36.080690300Z",
     "start_time": "2024-06-10T07:32:30.861986600Z"
    }
   },
   "id": "63675b258b8bbd2b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# To-Do\n",
    "# 00. make TCN-USAD(Done)\n",
    "# 01. prepare dataset(LEAD 1.0, EPIC, aihub)\n",
    "# 02. test and make a Smart Media Journal Paper\n",
    "\n",
    "# # 모델 가중치 학습 가능 여부 확인 코드\n",
    "# for weight in autoencoder.encoder.trainable_weights:\n",
    "#     print(f\"Weight name: {weight.name}, Trainable: {weight.trainable}\")\n",
    "# for weight in autoencoder.decoder.trainable_weights:\n",
    "#     print(f\"Weight name: {weight.name}, Trainable: {weight.trainable}\")\n",
    "# autoencoder.encoder.trainable_weights\n",
    "# autoencoder.decoder.trainable_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T07:11:20.397090300Z",
     "start_time": "2024-06-10T07:11:20.397090300Z"
    }
   },
   "id": "ce6d391142169953"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
